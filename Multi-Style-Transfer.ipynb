{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from collections import OrderedDict\n",
    "from functools import partial\n",
    "from random import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 224\n",
    "input_shape = (1, image_size, image_size, 3)\n",
    "\n",
    "# The VGG network requires the images to be zero mean\n",
    "# This the mean value of the training data of the ImageNet \n",
    "# training set, which will be used to make images zero mean\n",
    "vgg_mean = [123.68, 116.779, 103.939]\n",
    "\n",
    "# Hyperparameters used to define the final loss\n",
    "alpha = 1e3\n",
    "beta = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_weights(weights_file, end_layer):\n",
    "    \"\"\"\n",
    "    This function loads the weights_file and reads the weights until\n",
    "    the end_layer is reached.\n",
    "    \"\"\"\n",
    "    \n",
    "    layers = OrderedDict()\n",
    "    weights = np.load(weights_file)\n",
    "    sorted_weights = sorted(weights.items())\n",
    "\n",
    "    for i, (k, w) in enumerate(sorted_weights):\n",
    "        # If we have loaded the correct number of layers we stop\n",
    "        # to save memory\n",
    "        if sum([1 if len(v)==2 else 0 for v in layers.values()]) >= end_layer:\n",
    "            break\n",
    "        \n",
    "        if k[:-2] not in layers:\n",
    "            layers[k[:-2]] = {}\n",
    "            \n",
    "        if re.search(r'conv\\d+_\\d+_W', k) is not None:\n",
    "            layers[k[:-2]]['weights'] = w\n",
    "            print()\n",
    "        if re.search(r'conv\\d+_\\d+_b', k) is not None:\n",
    "            layers[k[:-2]]['bias'] = w\n",
    "  \n",
    "        print('Loading the weights for the layer {} and shape {}'.format(k,w.shape))\n",
    "\n",
    "    return layers\n",
    "\n",
    "# Making sure the weights are downloaded\n",
    "assert_msg = 'You need to download the vgg16_weights.npz'+\\\n",
    "                ' file by visiting https://www.cs.toronto.edu/~frossard/vgg16/vgg16_weights.npz'+\\\n",
    "                ' and place that in a folder called vgg in your project directory'\n",
    "assert os.path.exists(os.path.join('vgg','vgg16_weights.npz')), assert_msg\n",
    "\n",
    "vgg_layers = load_weights(os.path.join('vgg','vgg16_weights.npz'),7)\n",
    "def define_inputs(input_shape):\n",
    "    \"\"\"\n",
    "    This function defines the inputs (placeholders) and image to be generated (variable)\n",
    "    \"\"\"\n",
    "    \n",
    "    content = tf.placeholder(name='content', shape=input_shape, dtype=tf.float32)\n",
    "    style = tf.placeholder(name='style', shape=input_shape, dtype=tf.float32)\n",
    "    generated = tf.get_variable(name='generated', initializer=tf.random_normal_initializer(), \n",
    "                                shape=input_shape, dtype=tf.float32, trainable=True)\n",
    "    \n",
    "    return {'content': content, 'style': style, 'generated': generated}\n",
    "\n",
    "\n",
    "def define_tf_weights():\n",
    "    \"\"\"\n",
    "    This function defines the TensorFlow variables for VGG weights and biases\n",
    "    \"\"\"\n",
    "    \n",
    "    for k, w_dict in vgg_layers.items():\n",
    "        w, b = w_dict['weights'], w_dict['bias']\n",
    "        with tf.variable_scope(k):\n",
    "            tf.get_variable(name='weights', initializer=tf.constant(w, dtype=tf.float32), trainable=False)\n",
    "            tf.get_variable(name='bias', initializer=tf.constant(b, dtype=tf.float32), trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vgg_pooling_indices(sorted_layer_ids):\n",
    "    \"\"\"\n",
    "    A pooling layer appears at the end of each convolution group (i.e. conv<group>_<id>_W)\n",
    "    \"\"\"\n",
    "    pool_inds = []\n",
    "    prev_layer_id = int(sorted_layer_ids[0][4])\n",
    "    for ki, k in enumerate(sorted_layer_ids):\n",
    "        layer_id = int(k[4])\n",
    "        if layer_id != prev_layer_id:\n",
    "            pool_inds.append(ki-1)\n",
    "        prev_layer_id = layer_id\n",
    "    return pool_inds\n",
    "\n",
    "pool_inds = get_vgg_pooling_indices(list(vgg_layers.keys()))\n",
    "print('pooling indices are: {}'.format(pool_inds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vggnet(inp, layer_ids, pool_inds, on_cpu=False):\n",
    "    \"\"\" This function computes the output of the full VGGnet \"\"\"\n",
    "    outputs = OrderedDict()\n",
    "    \n",
    "    out = inp\n",
    "\n",
    "    for lid in layer_ids:\n",
    "        with tf.variable_scope(lid, reuse=tf.AUTO_REUSE):\n",
    "            print('Computing outputs for the layer {}'.format(lid))\n",
    "            w, b = tf.get_variable('weights'), tf.get_variable('bias')\n",
    "            out = tf.nn.conv2d(filter=w, input=out, strides=[1,1,1,1], padding='SAME')\n",
    "            out = tf.nn.relu(tf.nn.bias_add(value=out, bias=b))\n",
    "            outputs[lid] = out\n",
    "\n",
    "        if lid in pool_inds:\n",
    "            with tf.name_scope(lid.replace('conv','pool')):\n",
    "                out = tf.nn.avg_pool(input=out, ksize=[1,2,2,1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "                outputs[lid.replace('conv','pool')] = out\n",
    "\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_content_loss(inputs, layer_ids, pool_inds, c_weight):\n",
    "\n",
    "    c_outputs = build_vggnet(inputs[\"content\"], layer_ids, pool_inds)\n",
    "    g_outputs = build_vggnet(inputs[\"generated\"], layer_ids, pool_inds)\n",
    "\n",
    "    content_loss = c_weight * tf.reduce_mean(0.5*(list(c_outputs.values())[-1] - list(g_outputs.values())[-1])**2)\n",
    "    \n",
    "    return content_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_style_matrix(layer_out):\n",
    "    \"\"\"\n",
    "    This function computes the style matrix, which essentially computes\n",
    "    how correlated the activations of a given filter to all the other filers.\n",
    "    Therefore, if there are C channels, the matrix will be of size C x C\n",
    "    \"\"\"\n",
    "    n_channels = layer_out.get_shape().as_list()[-1]\n",
    "    unwrapped_out = tf.reshape(layer_out, [-1, n_channels])\n",
    "    style_matrix = tf.matmul(unwrapped_out, unwrapped_out, transpose_a=True)\n",
    "    return style_matrix\n",
    "\n",
    "def define_style_loss(inputs, layer_ids, pool_inds, s_weight, layer_weights=None):\n",
    "    \"\"\"\n",
    "    This function computes the style loss using the style matrix computed for\n",
    "    the style image and the generated image\n",
    "    \"\"\"\n",
    "    c_outputs = build_vggnet(inputs[\"style\"], layer_ids, pool_inds)\n",
    "    g_outputs = build_vggnet(inputs[\"generated\"], layer_ids, pool_inds)\n",
    "    \n",
    "    c_grams = [define_style_matrix(v) for v in list(c_outputs.values())]\n",
    "    g_grams = [define_style_matrix(v) for v in list(g_outputs.values())]\n",
    "    \n",
    "    if layer_weights is None:\n",
    "        style_loss =  s_weight * \\\n",
    "            tf.reduce_sum([(1.0/len(layer_ids)) * tf.reduce_mean((c - g)**2) for c,g in zip(c_grams, g_grams)])\n",
    "    else:\n",
    "        style_loss = s_weight * \\\n",
    "            tf.reduce_sum([tf.gather(layer_weights, i) * 0.5 * \\\n",
    "                            tf.reduce_mean((c - g)**2) for i,(c,g) in enumerate(zip(c_grams, g_grams))])\n",
    "    \n",
    "    return style_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_optimize(loss, learning_rate = 5.0):\n",
    "    \n",
    "    opt = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "    opt_op = opt.minimize(loss)\n",
    "    return opt_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(Image.open(os.path.join('data','style_1.jpg')))\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession(\n",
    "    config=tf.ConfigProto(allow_soft_placement=True)\n",
    ")\n",
    "\n",
    "def image_gen_func(data_dir, file_match_str, do_shuffle=True):\n",
    "    \"\"\"\n",
    "    This function returns a processed image and the color channel mean values.\n",
    "    This is a generator function used by the tf.data api.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Loading filenames\n",
    "    files = [f for f in os.listdir(data_dir) if f.startswith(file_match_str)]\n",
    "    if do_shuffle:\n",
    "        shuffle(files)\n",
    "    \n",
    "    mean = np.array([[vgg_mean]])\n",
    "    \n",
    "    # For each file preprocess the images and yield\n",
    "    for f in files:\n",
    "        img = Image.open(os.path.join(data_dir, f))\n",
    "        \n",
    "        width, height = img.size\n",
    "        \n",
    "        # We crop the image to a square by cropping on the longer axis\n",
    "        if width < height:\n",
    "            left,right = 0, width\n",
    "            top, bottom = (height-width)/2, ((height-width)/2) + width\n",
    "        elif width > height:\n",
    "            top, bottom = 0, height\n",
    "            left, right = (width - height)/2, ((width-height)/2) + height\n",
    "        else:\n",
    "            arr = np.array(img.resize((image_size,image_size))).astype(np.float32)\n",
    "            yield (arr, mean)\n",
    "        \n",
    "        arr = np.array(img.crop((left, top, right, bottom)).resize((image_size,image_size))).astype(np.float32)\n",
    "        yield (arr, mean)\n",
    "\n",
    "def load_images_iterator(gen_func, zero_mean=False):\n",
    "    \"\"\"\n",
    "    This function returns a dataset iterator of tf.data API\n",
    "    \"\"\"\n",
    "    image_dataset = tf.data.Dataset.from_generator(\n",
    "        gen_func, \n",
    "        output_types=(tf.float32, tf.float32), \n",
    "        output_shapes=(tf.TensorShape(input_shape[1:]), tf.TensorShape([1, 1, 3]))\n",
    "    )\n",
    "    \n",
    "    # If true, the mean will be subtracted\n",
    "    if zero_mean:\n",
    "        image_dataset = image_dataset.map(lambda x,y: (x - y, y))\n",
    "    \n",
    "    # We get on image at a time in a single batch\n",
    "    image_dataset = image_dataset.batch(1)\n",
    "    # Defining the iterator\n",
    "    iterator = image_dataset.make_one_shot_iterator()\n",
    "    return iterator\n",
    "\n",
    "# Defining partial functions to used by the tf.data.Dataset.from_generator()\n",
    "part_style_gen_func = partial(image_gen_func, 'data', \"style_\")\n",
    "part_content_gen_func = partial(image_gen_func, 'data', \"content_\")\n",
    "\n",
    "style_iter = load_images_iterator(part_style_gen_func, zero_mean=False)\n",
    "content_iter = load_images_iterator(part_content_gen_func, zero_mean=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_style_image = style_iter.get_next()\n",
    "next_content_image = content_iter.get_next()\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(sess.run(next_style_image)[0][0]/255.0)\n",
    "plt.axis('off')\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(sess.run(next_content_image)[0][0]/255.0)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "config = tf.ConfigProto(allow_soft_placement=True)\n",
    "sess = tf.InteractiveSession(config=config)\n",
    "\n",
    "# 1. Defining the input pipeline\n",
    "part_style_gen_func = partial(image_gen_func, 'data', \"style_\")\n",
    "part_content_gen_func = partial(image_gen_func, 'data', \"content_\")\n",
    "\n",
    "style_iter = load_images_iterator(part_style_gen_func, zero_mean=True)\n",
    "content_iter = load_images_iterator(part_content_gen_func, zero_mean=True)\n",
    "\n",
    "# 2. Defining the inputs and weights\n",
    "inputs = define_inputs(input_shape)\n",
    "define_tf_weights()\n",
    "\n",
    "layer_ids = list(vgg_layers.keys())\n",
    "\n",
    "# gen_ph is used to initialize the generated image with the pixel values \n",
    "# of the content image. You are welcome to try initializing with white noise\n",
    "# or the style image. The init_generated gives the initialization operation\n",
    "gen_ph = tf.placeholder(shape=input_shape, dtype=tf.float32)\n",
    "init_generated = tf.assign(inputs[\"generated\"], gen_ph)\n",
    "\n",
    "# 3. Losses\n",
    "# 3.1 Content loss\n",
    "c_loss = define_content_loss(\n",
    "    inputs=inputs, \n",
    "    layer_ids=layer_ids, pool_inds=pool_inds, c_weight=alpha\n",
    ")\n",
    "\n",
    "# 3.2 Style loss\n",
    "layer_weights_ph = tf.placeholder(shape=[len(layer_ids)], dtype=tf.float32, name='layer_weights')\n",
    "s_loss = define_style_loss(\n",
    "    inputs=inputs, \n",
    "    layer_ids=layer_ids, pool_inds=pool_inds, s_weight=beta, layer_weights=None\n",
    ")\n",
    "\n",
    "# 3.3 Total loss\n",
    "tot_loss = c_loss + s_loss\n",
    "\n",
    "# 4. Optimizer\n",
    "optimize = define_optimize(tot_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_image_with_restore(image, img_mean, save_path):\n",
    "    \"\"\" This function saves an image to disk \"\"\"\n",
    "    \n",
    "    image_restored = image + img_mean\n",
    "    image_restored = np.clip(image_restored,0,255.0)\n",
    "    image_restored = image_restored.astype('uint8')\n",
    "    Image.fromarray(image_restored).save(save_path)\n",
    "    \n",
    "    \n",
    "def get_layer_weights(type_id, num_layers):\n",
    "    \"\"\"\n",
    "    This function returns different layer weight schemes\n",
    "    to be experimented with. \n",
    "    \"\"\"\n",
    "    \n",
    "    if type_id == 0:\n",
    "        weights = np.arange(1,num_layers+1)**1.5\n",
    "        weights = weights/np.sum(weights)\n",
    "    if type_id == 1:\n",
    "        weights = np.arange(1,num_layers+1)**1.5\n",
    "        weights = weights/np.sum(weights)\n",
    "        weights = weights[::-1]\n",
    "        \n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del vgg_layers # Releasing memory\n",
    "\n",
    "n_iter = 500 # Number of optimizations steps per image\n",
    "\n",
    "\n",
    "for j in range(10):\n",
    "    print('\\nProcessing the {}th image ...'.format(j+1))\n",
    "    tf.global_variables_initializer().run()\n",
    "    (cont, cont_mean), (style, style_mean) = sess.run([content_iter.get_next(), style_iter.get_next()])\n",
    "    \n",
    "    # Saving the content and style images to disk\n",
    "    if not os.path.exists(os.path.join('data','gen_{}'.format(j))):\n",
    "        os.mkdir(os.path.join('data', 'gen_{}'.format(j)))\n",
    "    save_image_with_restore(cont[0], cont_mean[0], os.path.join('data', 'gen_{}'.format(j),'content.jpg'))\n",
    "    save_image_with_restore(style[0], style_mean[0], os.path.join('data', 'gen_{}'.format(j),'style.jpg'))\n",
    "    \n",
    "    # Initialize the generated image with the values of the content image\n",
    "    sess.run(init_generated, feed_dict={gen_ph:cont})\n",
    "    for i in range(n_iter):\n",
    "\n",
    "        l, _ = sess.run([tot_loss,optimize], feed_dict={\n",
    "            inputs[\"content\"]: cont,\n",
    "            inputs[\"style\"]: style,\n",
    "            layer_weights_ph: get_layer_weights(0, len(layer_ids))\n",
    "        })\n",
    "\n",
    "        # Printing out results and saving the generated image\n",
    "        if (i+1)%50==0:\n",
    "            print('\\tLoss at iteration {}: {}'.format(i+1, l))\n",
    "            gen_image = sess.run(inputs[\"generated\"])\n",
    "            save_image_with_restore(gen_image[0], cont_mean[0], os.path.join('data', 'gen_{}'.format(j),'gen_{}.jpg'.format(i+1)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('myenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f8590f55b7b21d1b98b5fc51d0fe581751d11f40e9603640142b25b227e4c74a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
